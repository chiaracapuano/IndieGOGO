{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook has the purpose of explaining how the app IndieGOGO works.\n",
    "\n",
    "The app determines whether a campaign on the IndieGOGO website is going to be successful or not.\n",
    "\n",
    "The strategy consists in:\n",
    "1. collecting a series of campaign ads from the IndieGOGO website,\n",
    "2. extract the terms frequency in the corpus, to be used as features\n",
    "3. train a logistic regression classifier using the success of a campaign as label (0 if unsuccessful, 1 if successful),\n",
    "4. using the model to determine whether a campaign (chosen by the user) will be successful or not.\n",
    "\n",
    "The campaign dataset is created scraping the IndieGOGO website with BeautifulSoup and Selenium. A future version of the app will only use BeautifulSoup, as it will rely on the page json file (more details below).\n",
    "\n",
    "As a first step, we connect to the Postgres database that contains the campaign dataset.\n",
    "The dataset is dumped in a pandas dataframe, and contains three columns: the first two are the two sections of the campaign corpus identified, the last is the percentage of money collected by the campaign."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sqlalchemy import create_engine\n",
    "import configparser\n",
    "import pandas as pd\n",
    "\n",
    "configParser = configparser.RawConfigParser()\n",
    "configFilePath = './login.config'\n",
    "configParser.read(configFilePath)\n",
    "user = configParser.get('dev-postgres-config', 'user')\n",
    "password = configParser.get('dev-postgres-config', 'pwd')\n",
    "host = configParser.get('dev-postgres-config', 'host')\n",
    "port = configParser.get('dev-postgres-config', 'port')\n",
    "\n",
    "print(\"Attempt to connect to PSQL at {}:{} as user '{}'\".format(host, port, user))\n",
    "\n",
    "engine = create_engine(\n",
    "    'postgresql+psycopg2://' + user + ':' + password + '@' + host + ':' + port + '/indiegogo_url')\n",
    "\n",
    "df = pd.read_sql_query('select * from \"idf_ml_set_complete\"', con=engine)\n",
    "df = df.fillna(\"0\")\n",
    "print()\n",
    "print(\"Head of df:\")\n",
    "print(df.head())\n",
    "print()\n",
    "print(\"Length of df:\")\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to connect to PSQL at postgres:5432 as user 'postgres'\n",
      "\n",
      "Head of df:\n",
      "  lower_case_span                                     lower_case_div  \\\n",
      "0              {}  {\"why micky needs help.\\nyesterday, my dog was...   \n",
      "1              {}  {\"\\nshort summary\\ncontributors fund ideas the...   \n",
      "2              {}  {\"\\n\\nfrankie needs all of the love and help h...   \n",
      "3              {}  {\"\\nannouncement 5/17/13\\nwe have surpassed ou...   \n",
      "4              {}  {\"i am a single mother that can't afford the c...   \n",
      "\n",
      "  collected_percentage  \n",
      "0                  100  \n",
      "1                  130  \n",
      "2                   80  \n",
      "3                  128  \n",
      "4                  105  \n",
      "\n",
      "Length of df:\n",
      "2351\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Usually the campaign ads contain an \"Overview\" section that is stored in the column \"lower_case_span\" and the actual ad corpus contained in \"lower_case_div\".\n",
    "A lot of the websites scraped did not contain an overview section, therefore a lot of the respective rows are empty.\n",
    "\n",
    "The second step consists in the initialization of the TfidfVectorizer.\n",
    "The vectorizer will be used to build a term frequency matrix,\n",
    "which will have as many rows as the campaign ads scraped, and the\n",
    "columns will correspond to the unigrams and bigrams that are present in less than 95% of the documents\n",
    "but more than 3% of them. Also, stopwords are excluded.\n",
    "\n",
    "In obtaining the terms frequency matrix, 'lower_case_span' and 'lower_case_div' are joined together.\n",
    "\n",
    "Imposing these thresholds helps keeping the dimension of the vectorizer matrix contained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer initialized.\n",
      "Building the term frequency matrix.\n",
      "\n",
      "Dimensions of tfidf_matrix:\n",
      "(2351, 1562)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                             ngram_range=(1, 2),\n",
    "                             max_df=0.95,\n",
    "                             min_df=0.03,\n",
    "                             stop_words=stopwords_list)\n",
    "\n",
    "print('Vectorizer initialized.')\n",
    "print('Building the term frequency matrix.')\n",
    "print()\n",
    "#'lower_case_span' and 'lower_case_div' are joined together.\n",
    "tfidf_matrix = vectorizer.fit_transform(df['lower_case_span'] + \" \" + df['lower_case_div'])\n",
    "sdf = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix)\n",
    "print(\"Dimensions of tfidf_matrix:\")\n",
    "print(sdf.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The matrix contains the features that will be used to train the logistic regression classifier.\n",
    "\n",
    "Now it is the time to add the label column: whenever the collected percentage is less than 100% the campaign will be considered unsuccessful, therefore the label will be 0, 1 otherwise.\n",
    "\n",
    "The percentage of money raised by the campaign is a string in which the thousand separator is a comma rather than a dot. This will be a problem when casting the column to float,\n",
    "so before that we replace commas with dots across all the column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of tfidf_matrix:\n",
      "(2351, 1564)\n"
     ]
    }
   ],
   "source": [
    "#Addition of 'collected_percentage' column.\n",
    "sdf['collected_percentage'] = df['collected_percentage']\n",
    "\n",
    "#Replacement of commas with dots\n",
    "sdf['collected_percentage'] = sdf['collected_percentage'].str.replace(\",\", \".\")\n",
    "\n",
    "#Cast the column to float, create new column with 1 or 0\n",
    "# based on the campaign success.\n",
    "sdf['collected_percentage_binary'] = [1 if x > 100 else 0 for x in\n",
    "                                      sdf['collected_percentage'].astype(float)]\n",
    "print(\"Dimensions of tfidf_matrix:\")\n",
    "\n",
    "print(sdf.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The matrix is fed into a logistic regression classifier, that performs a 5-fold cross validation.\n",
    "Because the labels are imbalanced, class weights are added.\n",
    "\n",
    "The score of the model is returned, with the scoring method being the area under the ROC curve."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ones: 1646\n",
      "Number of zeroes: 705\n",
      "Finished training classifier.\n",
      "Score: 0.9999991382504761\n"
     ]
    }
   ],
   "source": [
    "#Proof of class imbalance:\n",
    "ones_weight = len(sdf[sdf['collected_percentage_binary'] == 1])\n",
    "zeroes_weight = len(sdf[sdf['collected_percentage_binary'] == 0])\n",
    "print(\"Number of ones:\", ones_weight)\n",
    "print(\"Number of zeroes:\", zeroes_weight)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "X = sdf.drop(columns=[\"collected_percentage\", \"collected_percentage_binary\"])\n",
    "y = sdf['collected_percentage_binary']\n",
    "clf = LogisticRegressionCV(cv=5, class_weight= 'balanced', scoring='roc_auc', max_iter=1000).fit(X, y)\n",
    "\n",
    "print('Finished training classifier.')\n",
    "print('Score:', clf.score(X, y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the classifier trained, we can proceed\n",
    "with testing the model using a campaign ad chosen by the user.\n",
    "\n",
    "The user provides the link to a campaign ad, which is scraped using BeautifulSoup.\n",
    "Rather than using Selenium to load the parts of the page accessible only after puc=shing the button \"Load More\",\n",
    "the program extracts the project_id and proceeds with scraping the webpage in json format accessible that the project id gives access to."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351\n",
      "made matrix\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "#Link to the campaign as chosen by the user.\n",
    "url = 'https://www.indiegogo.com//projects/homefarm-the-ultimate-in-home-cultivation-food-cooking'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "json_data = soup.find('script', text=re.compile(\"//<!\\[CDATA\\[\"))\n",
    "pattern = ',\"project_id\":(.*)};gon.tracking_info={'\n",
    "#The webpage is scraped to obtain the project_id\n",
    "project_id = re.search(pattern, str(json_data)).group(1)\n",
    "#The project id is used to access the json format of the webpage, containing the\n",
    "#whole ad corpus.\n",
    "page = requests.get(\"https://www.indiegogo.com/private_api/campaigns/\" + project_id + \"/description\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "dict_json = json.loads(str(soup))\n",
    "html_str = dict_json['response']['description_html']\n",
    "#The ad corpus is transformed into a string\n",
    "soup_text = BeautifulSoup(html_str, \"html.parser\").get_text()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The corpus of the desired ad website has to be integrated with the whole\n",
    "campaign dataset in order to get a consistent tfidf matrix.\n",
    "\n",
    "The newly scraped ad corpus is therefore inserted into a pandas dataframe and appended to the campaign dataset\n",
    "\n",
    "Notice that because the scraping method changed, the newly scraped website will not have 'lower_case_span' and 'lower_case_div'\n",
    "components, but just a single string that encompasses the whole ad.\n",
    "\n",
    "That is why 'lower_case_span' is set to be an empty string, while 'lower_case_div' consists of the whole corpus.\n",
    "\n",
    "The collected percentage of the campaign is set to np.Nan.\n",
    "\n",
    "The vectorized already used to create the TF-IDF matrix is re-used in order to extract the features of the user input website consistently\n",
    "with the rest of the dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "temp_dict = [\n",
    "    {\n",
    "        'lower_case_span': str(),\n",
    "        'lower_case_div': soup_text,\n",
    "        'collected_percentage': np.NaN\n",
    "    }\n",
    "]\n",
    "\n",
    "temp = pd.DataFrame.from_records(temp_dict)\n",
    "df_to_pred = pd.concat([df, temp])\n",
    "df_to_pred = df_to_pred.reset_index(drop=True)\n",
    "#Loading the vectorized previously used to create the TD-IDF matrix,\n",
    "#to obtain consistent features and terms frequencies.\n",
    "tfidf_matrix_to_pred = vectorizer.fit_transform(df_to_pred['lower_case_span'] + \" \" + df_to_pred['lower_case_div'])\n",
    "print(\"Matrix created.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix created.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "As before, the matrix is transformed into a dataframe, and the 'collected_percentage' column is added."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sdf = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix_to_pred)\n",
    "sdf['collected_percentage'] = df_to_pred['collected_percentage']\n",
    "\n",
    "print(\"Dimensions of tfidf_matrix_to_pred:\")\n",
    "print(sdf.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keeping in mind that the dataframe entrance we are interested in for our prediction is the only one with a np.Nan value as collected percentage,\n",
    "we only retain the dataframe row having a Nan \"collected_percentage\".\n",
    "\n",
    "The collected_percentage column is then dropped, so that we are left with only the features\n",
    "of the user input campaign ad.\n",
    "\n",
    "Finally, the prediction is displayed, showing \"The campaign will be unsuccessful :(\" if the predicted value is 0,\n",
    "\"The campaign will be successful!!\" otherwise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Selecting the Nan collected_percentage value of all the dataframe.\n",
    "X_to_pred = sdf[sdf.isnull().any(1)]\n",
    "#Eliminate collected_percentage to only retain the ad's features.\n",
    "X_to_pred = X_to_pred.drop(columns=[\"collected_percentage\"])\n",
    "#Prediction\n",
    "res = clf.predict(X_to_pred)\n",
    "\n",
    "if res[0] == 0:\n",
    "    output_logreg = \"The campaign will be unsuccessful :(\"\n",
    "else:\n",
    "    output_logreg = \"The campaign will be successful!!\"\n",
    "\n",
    "print(output_logreg)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The campaign will be unsuccessful :(\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}